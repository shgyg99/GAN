{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!apt-get -y install -qq -q aria2\n!pip uninstall -q wandb -y\n!pip install -q wandb==0.15.12","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Zfnuoj7qNyx","outputId":"55e88891-13a6-4c67-e91f-ea9c1b8aba60","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:15:19.978920Z","iopub.execute_input":"2025-02-03T04:15:19.979213Z","iopub.status.idle":"2025-02-03T04:15:51.384604Z","shell.execute_reply.started":"2025-02-03T04:15:19.979186Z","shell.execute_reply":"2025-02-03T04:15:51.383611Z"}},"outputs":[{"name":"stdout","text":"Selecting previously unselected package libc-ares2:amd64.\n(Reading database ... 127400 files and directories currently installed.)\nPreparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\nUnpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\nSelecting previously unselected package libaria2-0:amd64.\nPreparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\nUnpacking libaria2-0:amd64 (1.36.0-1) ...\nSelecting previously unselected package aria2.\nPreparing to unpack .../aria2_1.36.0-1_amd64.deb ...\nUnpacking aria2 (1.36.0-1) ...\nSetting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\nSetting up libaria2-0:amd64 (1.36.0-1) ...\nSetting up aria2 (1.36.0-1) ...\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.4) ...\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -d /kaggle/working/ -o stable-diffusion-webui.zip \\\n  \"https://github.com/AUTOMATIC1111/stable-diffusion-webui/archive/refs/heads/master.zip\"\n!unzip -q /kaggle/working/stable-diffusion-webui.zip -d /kaggle/working/","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZy8d-ksq49N","outputId":"97a2ee44-b4f9-4f12-c3d8-31da769073a6","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:15:51.385615Z","iopub.execute_input":"2025-02-03T04:15:51.386008Z","iopub.status.idle":"2025-02-03T04:15:52.055151Z","shell.execute_reply.started":"2025-02-03T04:15:51.385946Z","shell.execute_reply":"2025-02-03T04:15:52.054041Z"}},"outputs":[{"name":"stdout","text":"\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n2198d2|\u001b[1;32mOK\u001b[0m  |    35MiB/s|/kaggle/working//stable-diffusion-webui.zip\n\nStatus Legend:\n(OK):download completed.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%cd /kaggle/working/stable-diffusion-webui-master\n!mkdir -p models/Stable-diffusion","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ff3Bfjywq9ZP","outputId":"89b25e09-cb6c-4468-9cf8-8f5ddef88d46","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:15:52.056232Z","iopub.execute_input":"2025-02-03T04:15:52.056485Z","iopub.status.idle":"2025-02-03T04:15:52.175997Z","shell.execute_reply.started":"2025-02-03T04:15:52.056463Z","shell.execute_reply":"2025-02-03T04:15:52.175195Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/stable-diffusion-webui-master\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -d /kaggle/working/stable-diffusion-webui-master/models/Stable-diffusion \\\n  -o v1-5-pruned-emaonly.safetensors \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvsLSFp-rIuN","outputId":"189afe2c-632a-4890-e005-b26bddb05111","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:16:12.738494Z","iopub.execute_input":"2025-02-03T04:16:12.738783Z","iopub.status.idle":"2025-02-03T04:16:39.922542Z","shell.execute_reply.started":"2025-02-03T04:16:12.738758Z","shell.execute_reply":"2025-02-03T04:16:39.921674Z"}},"outputs":[{"name":"stdout","text":"\u001b[35m[\u001b[0m#8fd59b 3.8GiB/3.9GiB\u001b[36m(96%)\u001b[0m CN:16 DL:\u001b[32m407MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0m\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n8fd59b|\u001b[1;32mOK\u001b[0m  |   401MiB/s|/kaggle/working/stable-diffusion-webui-master/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors\n\nStatus Legend:\n(OK):download completed.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"! pip install -q gdown\n!mkdir -p /kaggle/working/lora_art_model\n\nimport gdown\n!gdown --folder --id 1A08jlg9LN5SlLXhpL-ZPQ6iJ3vB3vWsQ -O /kaggle/working/lora_art_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T14:41:36.459767Z","iopub.execute_input":"2025-02-02T14:41:36.460140Z","iopub.status.idle":"2025-02-02T14:41:52.643820Z","shell.execute_reply.started":"2025-02-02T14:41:36.460109Z","shell.execute_reply":"2025-02-02T14:41:52.642784Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nRetrieving folder contents\nProcessing file 1g9ZRUEIf15CJw7ea2_yRPpWt1iJGp73Z 1.safetensors\nProcessing file 1VSpGBXhDwFnATSzJRjool3-Cw6bWjsWN 2.safetensors\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=1g9ZRUEIf15CJw7ea2_yRPpWt1iJGp73Z\nTo: /kaggle/working/lora_art_model/1.safetensors\n100%|██████████████████████████████████████| 66.2M/66.2M [00:00<00:00, 90.0MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1VSpGBXhDwFnATSzJRjool3-Cw6bWjsWN\nTo: /kaggle/working/lora_art_model/2.safetensors\n100%|██████████████████████████████████████| 66.2M/66.2M [00:00<00:00, 75.4MB/s]\nDownload completed\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!mkdir -p /kaggle/working/stable-diffusion-webui-master/models/Lora\n!cp /kaggle/working/lora_art_model/1.safetensors /kaggle/working/stable-diffusion-webui-master/models/Lora/\n!cp /kaggle/working/lora_art_model/2.safetensors /kaggle/working/stable-diffusion-webui-master/models/Lora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T14:42:33.450182Z","iopub.execute_input":"2025-02-02T14:42:33.450556Z","iopub.status.idle":"2025-02-02T14:42:33.901154Z","shell.execute_reply.started":"2025-02-02T14:42:33.450526Z","shell.execute_reply":"2025-02-02T14:42:33.900227Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!COMMANDLINE_ARGS=\"--share --disable-safe-unpickle\" python /kaggle/working/stable-diffusion-webui-master/launch.py","metadata":{"id":"vkReUS4krR6z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b641a97-0e9c-4c6c-83c4-61a728446776","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:26:03.075102Z","iopub.execute_input":"2025-02-03T04:26:03.075424Z"}},"outputs":[{"name":"stdout","text":"fatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\nfatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\nPython 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\nVersion: 1.10.1\nCommit hash: <none>\nInstalling clip\nInstalling open_clip\nCloning assets into /kaggle/working/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets...\nCloning into '/kaggle/working/stable-diffusion-webui-master/repositories/stable-diffusion-webui-assets'...\nremote: Enumerating objects: 20, done.\u001b[K\nremote: Counting objects: 100% (20/20), done.\u001b[K\nremote: Compressing objects: 100% (18/18), done.\u001b[K\nremote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (20/20), 132.70 KiB | 6.98 MiB/s, done.\nCloning Stable Diffusion into /kaggle/working/stable-diffusion-webui-master/repositories/stable-diffusion-stability-ai...\nCloning into '/kaggle/working/stable-diffusion-webui-master/repositories/stable-diffusion-stability-ai'...\nremote: Enumerating objects: 580, done.\u001b[K\nremote: Counting objects: 100% (2/2), done.\u001b[K\nremote: Compressing objects: 100% (2/2), done.\u001b[K\nremote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 578 (from 2)\u001b[K\nReceiving objects: 100% (580/580), 73.44 MiB | 45.69 MiB/s, done.\nResolving deltas: 100% (283/283), done.\nCloning Stable Diffusion XL into /kaggle/working/stable-diffusion-webui-master/repositories/generative-models...\nCloning into '/kaggle/working/stable-diffusion-webui-master/repositories/generative-models'...\nremote: Enumerating objects: 1064, done.\u001b[K\nremote: Counting objects: 100% (57/57), done.\u001b[K\nremote: Compressing objects: 100% (28/28), done.\u001b[K\nremote: Total 1064 (delta 35), reused 29 (delta 29), pack-reused 1007 (from 3)\u001b[K\nReceiving objects: 100% (1064/1064), 53.61 MiB | 50.09 MiB/s, done.\nResolving deltas: 100% (545/545), done.\nCloning K-diffusion into /kaggle/working/stable-diffusion-webui-master/repositories/k-diffusion...\nCloning into '/kaggle/working/stable-diffusion-webui-master/repositories/k-diffusion'...\nremote: Enumerating objects: 1350, done.\u001b[K\nremote: Counting objects: 100% (651/651), done.\u001b[K\nremote: Compressing objects: 100% (87/87), done.\u001b[K\nremote: Total 1350 (delta 608), reused 566 (delta 564), pack-reused 699 (from 1)\u001b[K\nReceiving objects: 100% (1350/1350), 239.59 KiB | 10.42 MiB/s, done.\nResolving deltas: 100% (948/948), done.\nCloning BLIP into /kaggle/working/stable-diffusion-webui-master/repositories/BLIP...\nCloning into '/kaggle/working/stable-diffusion-webui-master/repositories/BLIP'...\nremote: Enumerating objects: 277, done.\u001b[K\nremote: Counting objects: 100% (183/183), done.\u001b[K\nremote: Compressing objects: 100% (46/46), done.\u001b[K\nremote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)\u001b[K\nReceiving objects: 100% (277/277), 7.04 MiB | 42.13 MiB/s, done.\nResolving deltas: 100% (152/152), done.\nInstalling requirements\nLaunching Web UI with arguments: --share --disable-safe-unpickle\n2025-02-03 04:27:07.552381: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-02-03 04:27:07.574634: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-02-03 04:27:07.581158: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\nno module 'xformers'. Processing without...\nno module 'xformers'. Processing without...\nNo module 'xformers'. Proceeding without it.\nCalculating sha256 for /kaggle/working/stable-diffusion-webui-master/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors: Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://1e94b66d2d3e1bfa57.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\nStartup time: 72.1s (prepare environment: 56.3s, import torch: 6.0s, import gradio: 1.2s, setup paths: 3.7s, initialize shared: 0.2s, other imports: 0.5s, load scripts: 0.7s, create ui: 0.5s, gradio launch: 2.9s).\n6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa\nLoading weights [6ce0161689] from /kaggle/working/stable-diffusion-webui-master/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors\nCreating model from config: /kaggle/working/stable-diffusion-webui-master/configs/v1-inference.yaml\n/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nconfig.json: 100%|█████████████████████████| 4.52k/4.52k [00:00<00:00, 17.9MB/s]\nApplying attention optimization: Doggettx... done.\nModel loaded in 17.7s (calculate hash: 13.0s, create model: 0.7s, apply weights to model: 3.6s, calculate empty prompt: 0.1s).\n/kaggle/working/stable-diffusion-webui-master/modules/safe.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return unsafe_torch_load(filename, *args, **kwargs)\n  0%|                                                    | 0/20 [00:00<?, ?it/s]\n  5%|██▏                                         | 1/20 [00:02<00:53,  2.79s/it]\u001b[A\n 10%|████▍                                       | 2/20 [00:03<00:24,  1.35s/it]\u001b[A\n 15%|██████▌                                     | 3/20 [00:03<00:15,  1.12it/s]\u001b[A\n 20%|████████▊                                   | 4/20 [00:03<00:10,  1.48it/s]\u001b[A\n 25%|███████████                                 | 5/20 [00:04<00:08,  1.80it/s]\u001b[A\n 30%|█████████████▏                              | 6/20 [00:04<00:06,  2.07it/s]\u001b[A\n 35%|███████████████▍                            | 7/20 [00:04<00:05,  2.29it/s]\u001b[A\n 40%|█████████████████▌                          | 8/20 [00:05<00:04,  2.46it/s]\u001b[A\n 45%|███████████████████▊                        | 9/20 [00:05<00:04,  2.58it/s]\u001b[A\n 50%|█████████████████████▌                     | 10/20 [00:05<00:03,  2.68it/s]\u001b[A\n 55%|███████████████████████▋                   | 11/20 [00:06<00:03,  2.75it/s]\u001b[A\n 60%|█████████████████████████▊                 | 12/20 [00:06<00:02,  2.80it/s]\u001b[A\n 65%|███████████████████████████▉               | 13/20 [00:06<00:02,  2.83it/s]\u001b[A\n 70%|██████████████████████████████             | 14/20 [00:07<00:02,  2.84it/s]\u001b[A\n 75%|████████████████████████████████▎          | 15/20 [00:07<00:01,  2.86it/s]\u001b[A\n 80%|██████████████████████████████████▍        | 16/20 [00:07<00:01,  2.88it/s]\u001b[A\n 85%|████████████████████████████████████▌      | 17/20 [00:08<00:01,  2.89it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 18/20 [00:08<00:00,  2.90it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 19/20 [00:08<00:00,  2.90it/s]\u001b[A\n100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.15it/s]\u001b[A\n\nTotal progress: 100%|███████████████████████████| 20/20 [00:06<00:00,  2.86it/s]\u001b[A\n  0%|                                                    | 0/20 [00:00<?, ?it/s]\n  5%|██▏                                         | 1/20 [00:00<00:05,  3.76it/s]\u001b[A\n 10%|████▍                                       | 2/20 [00:00<00:05,  3.20it/s]\u001b[A\n 15%|██████▌                                     | 3/20 [00:00<00:05,  3.06it/s]\u001b[A\n 20%|████████▊                                   | 4/20 [00:01<00:05,  3.01it/s]\u001b[A\n 25%|███████████                                 | 5/20 [00:01<00:05,  2.97it/s]\u001b[A\n 30%|█████████████▏                              | 6/20 [00:01<00:04,  2.95it/s]\u001b[A\n 35%|███████████████▍                            | 7/20 [00:02<00:04,  2.94it/s]\u001b[A\n 40%|█████████████████▌                          | 8/20 [00:02<00:04,  2.93it/s]\u001b[A\n 45%|███████████████████▊                        | 9/20 [00:03<00:03,  2.93it/s]\u001b[A\n 50%|█████████████████████▌                     | 10/20 [00:03<00:03,  2.92it/s]\u001b[A\n 55%|███████████████████████▋                   | 11/20 [00:03<00:03,  2.92it/s]\u001b[A\n 60%|█████████████████████████▊                 | 12/20 [00:04<00:02,  2.92it/s]\u001b[A\n 65%|███████████████████████████▉               | 13/20 [00:04<00:02,  2.92it/s]\u001b[A\n 70%|██████████████████████████████             | 14/20 [00:04<00:02,  2.92it/s]\u001b[A\n 75%|████████████████████████████████▎          | 15/20 [00:05<00:01,  2.91it/s]\u001b[A\n 80%|██████████████████████████████████▍        | 16/20 [00:05<00:01,  2.91it/s]\u001b[A\n 85%|████████████████████████████████████▌      | 17/20 [00:05<00:01,  2.91it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 18/20 [00:06<00:00,  2.92it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 19/20 [00:06<00:00,  2.92it/s]\u001b[A\n100%|███████████████████████████████████████████| 20/20 [00:06<00:00,  2.95it/s]\u001b[A\n\nTotal progress: 100%|███████████████████████████| 20/20 [00:06<00:00,  2.86it/s]\u001b[A\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working\n!git clone https://github.com/kohya-ss/sd-scripts.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3XUIaUWVMmJ","outputId":"6641c8f1-488b-48e8-fa6e-13c6312e0e57","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:16:39.923976Z","iopub.execute_input":"2025-02-03T04:16:39.924353Z","iopub.status.idle":"2025-02-03T04:16:41.656057Z","shell.execute_reply.started":"2025-02-03T04:16:39.924319Z","shell.execute_reply":"2025-02-03T04:16:41.655188Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'sd-scripts'...\nremote: Enumerating objects: 9036, done.\u001b[K\nremote: Counting objects: 100% (543/543), done.\u001b[K\nremote: Compressing objects: 100% (102/102), done.\u001b[K\nremote: Total 9036 (delta 503), reused 441 (delta 441), pack-reused 8493 (from 2)\u001b[K\nReceiving objects: 100% (9036/9036), 11.17 MiB | 26.54 MiB/s, done.\nResolving deltas: 100% (6526/6526), done.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%cd sd-scripts\n!pip install -r requirements.txt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s1ZiaFhjwWoR","outputId":"f538f513-5f97-4ae8-d041-4402bdde28b5","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:16:41.657513Z","iopub.execute_input":"2025-02-03T04:16:41.657812Z","iopub.status.idle":"2025-02-03T04:17:10.641461Z","shell.execute_reply.started":"2025-02-03T04:16:41.657781Z","shell.execute_reply":"2025-02-03T04:17:10.640646Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/sd-scripts\nObtaining file:///kaggle/working/sd-scripts (from -r requirements.txt (line 42))\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting accelerate==0.30.0 (from -r requirements.txt (line 1))\n  Downloading accelerate-0.30.0-py3-none-any.whl.metadata (19 kB)\nCollecting transformers==4.44.0 (from -r requirements.txt (line 2))\n  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting diffusers==0.25.0 (from diffusers[torch]==0.25.0->-r requirements.txt (line 3))\n  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\nCollecting ftfy==6.1.1 (from -r requirements.txt (line 4))\n  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\nCollecting opencv-python==4.8.1.78 (from -r requirements.txt (line 6))\n  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nCollecting einops==0.7.0 (from -r requirements.txt (line 7))\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nCollecting pytorch-lightning==1.9.0 (from -r requirements.txt (line 8))\n  Downloading pytorch_lightning-1.9.0-py3-none-any.whl.metadata (23 kB)\nCollecting bitsandbytes==0.44.0 (from -r requirements.txt (line 9))\n  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nCollecting prodigyopt==1.0 (from -r requirements.txt (line 10))\n  Downloading prodigyopt-1.0-py3-none-any.whl.metadata (1.2 kB)\nCollecting lion-pytorch==0.0.6 (from -r requirements.txt (line 11))\n  Downloading lion_pytorch-0.0.6-py3-none-any.whl.metadata (620 bytes)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.17.1)\nCollecting safetensors==0.4.2 (from -r requirements.txt (line 13))\n  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting altair==4.2.2 (from -r requirements.txt (line 15))\n  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\nCollecting easygui==0.98.3 (from -r requirements.txt (line 16))\n  Downloading easygui-0.98.3-py2.py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.10.2)\nCollecting voluptuous==0.13.1 (from -r requirements.txt (line 18))\n  Downloading voluptuous-0.13.1-py3-none-any.whl.metadata (20 kB)\nCollecting huggingface-hub==0.24.5 (from -r requirements.txt (line 19))\n  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: imagesize==1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.4.1)\nCollecting rich==13.7.0 (from -r requirements.txt (line 40))\n  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (3.16.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (2.32.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.44.0->-r requirements.txt (line 2))\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (4.67.1)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (8.5.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (11.0.0)\nRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 4)) (0.2.13)\nRequirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2024.9.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.6.1)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (0.11.9)\nRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (0.4)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (3.1.4)\nRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (4.23.0)\nRequirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (2.2.2)\nRequirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (0.12.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.0->-r requirements.txt (line 40)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.0->-r requirements.txt (line 40)) (2.18.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.7)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.1.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (3.11.10)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (24.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (0.22.3)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.0->-r requirements.txt (line 40)) (0.1.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 15)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 15)) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 15)) (2024.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (3.4.2)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 12)) (3.0.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (3.21.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (2024.12.14)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.0.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.18.3)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->accelerate==0.30.0->-r requirements.txt (line 1)) (2024.2.0)\nDownloading accelerate-0.30.0-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading prodigyopt-1.0-py3-none-any.whl (5.5 kB)\nDownloading lion_pytorch-0.0.6-py3-none-any.whl (4.2 kB)\nDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\nDownloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: voluptuous, library, easygui, safetensors, prodigyopt, ftfy, einops, rich, huggingface-hub, tokenizers, lion-pytorch, diffusers, accelerate, transformers, pytorch-lightning, opencv-python, bitsandbytes, altair\n  Running setup.py develop for library\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.4.5\n    Uninstalling safetensors-0.4.5:\n      Successfully uninstalled safetensors-0.4.5\n  Attempting uninstall: einops\n    Found existing installation: einops 0.8.0\n    Uninstalling einops-0.8.0:\n      Successfully uninstalled einops-0.8.0\n  Attempting uninstall: rich\n    Found existing installation: rich 13.9.4\n    Uninstalling rich-13.9.4:\n      Successfully uninstalled rich-13.9.4\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.27.0\n    Uninstalling huggingface-hub-0.27.0:\n      Successfully uninstalled huggingface-hub-0.27.0\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: diffusers\n    Found existing installation: diffusers 0.31.0\n    Uninstalling diffusers-0.31.0:\n      Successfully uninstalled diffusers-0.31.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.2.1\n    Uninstalling accelerate-1.2.1:\n      Successfully uninstalled accelerate-1.2.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.5.0.post0\n    Uninstalling pytorch-lightning-2.5.0.post0:\n      Successfully uninstalled pytorch-lightning-2.5.0.post0\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.10.0.84\n    Uninstalling opencv-python-4.10.0.84:\n      Successfully uninstalled opencv-python-4.10.0.84\n  Attempting uninstall: altair\n    Found existing installation: altair 5.5.0\n    Uninstalling altair-5.5.0:\n      Successfully uninstalled altair-5.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npeft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.24.5 which is incompatible.\npymc 5.19.1 requires rich>=13.7.1, but you have rich 13.7.0 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.30.0 altair-4.2.2 bitsandbytes-0.44.0 diffusers-0.25.0 easygui-0.98.3 einops-0.7.0 ftfy-6.1.1 huggingface-hub-0.24.5 library-0.0.0 lion-pytorch-0.0.6 opencv-python-4.8.1.78 prodigyopt-1.0 pytorch-lightning-1.9.0 rich-13.7.0 safetensors-0.4.2 tokenizers-0.19.1 transformers-4.44.0 voluptuous-0.13.1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"! pip install gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:17:10.642593Z","iopub.execute_input":"2025-02-03T04:17:10.642882Z","iopub.status.idle":"2025-02-03T04:17:13.921673Z","shell.execute_reply.started":"2025-02-03T04:17:10.642845Z","shell.execute_reply":"2025-02-03T04:17:13.920590Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!rm -rf /kaggle/working/datasets/2_images/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:20:58.455506Z","iopub.execute_input":"2025-02-03T04:20:58.455842Z","iopub.status.idle":"2025-02-03T04:20:58.573623Z","shell.execute_reply.started":"2025-02-03T04:20:58.455811Z","shell.execute_reply":"2025-02-03T04:20:58.572631Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"!mkdir -p /kaggle/working/datasets/1_images\n# !mkdir -p /kaggle/working/datasets/2_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:17:16.684611Z","iopub.execute_input":"2025-02-03T04:17:16.684991Z","iopub.status.idle":"2025-02-03T04:17:16.921263Z","shell.execute_reply.started":"2025-02-03T04:17:16.684964Z","shell.execute_reply":"2025-02-03T04:17:16.919733Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import gdown\n!gdown --folder --id 15-stXYhF49Wxqpel4Di9H3KpuAz3JVCJ -O /kaggle/working/datasets/1_images\n# !gdown --folder --id 1C1RiHt4eJdpNtLTeCD3RA4EoYVj2hz2c -O /kaggle/working/datasets/2_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:17:59.674867Z","iopub.execute_input":"2025-02-03T04:17:59.675206Z","iopub.status.idle":"2025-02-03T04:18:09.400689Z","shell.execute_reply.started":"2025-02-03T04:17:59.675181Z","shell.execute_reply":"2025-02-03T04:18:09.399597Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nRetrieving folder contents\nProcessing file 10c5uW0yNCMao2xrfnAVgKTDPpqcd9xiB im (1).png\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=10c5uW0yNCMao2xrfnAVgKTDPpqcd9xiB\nTo: /kaggle/working/datasets/1_images/im (1).png\n100%|███████████████████████████████████████| 1.76M/1.76M [00:00<00:00, 179MB/s]\nDownload completed\n/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nRetrieving folder contents\nProcessing file 1MvrI9d81mcCKOncapTjO9iV40CavI0-n im (1).png\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=1MvrI9d81mcCKOncapTjO9iV40CavI0-n\nTo: /kaggle/working/datasets/2_images/im (1).png\n100%|███████████████████████████████████████| 1.30M/1.30M [00:00<00:00, 112MB/s]\nDownload completed\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!mkdir -p /kaggle/working/lora_art_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:18:16.199421Z","iopub.execute_input":"2025-02-03T04:18:16.200143Z","iopub.status.idle":"2025-02-03T04:18:16.318160Z","shell.execute_reply.started":"2025-02-03T04:18:16.200112Z","shell.execute_reply":"2025-02-03T04:18:16.317222Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!accelerate launch /kaggle/working/sd-scripts/train_network.py \\\n  --pretrained_model_name_or_path=/kaggle/working/stable-diffusion-webui-master/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors \\\n  --train_data_dir=/kaggle/working/datasets/ \\\n  --output_dir=/kaggle/working/lora_art_model/ \\\n  --gradient_accumulation_steps=1 \\\n  --resolution=256,256 \\\n  --enable_bucket \\\n  --network_module=networks.lora \\\n  --network_dim=32 \\\n  --network_alpha=16 \\\n  --learning_rate=1e-4 \\\n  --train_batch_size=2 \\\n  --max_train_steps=200 \\\n  --save_every_n_steps=100","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBOsuw1HW8Dv","outputId":"b1b850a5-d8fa-4ca1-8252-edb01a34a9c8","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:21:35.638563Z","iopub.execute_input":"2025-02-03T04:21:35.638937Z","iopub.status.idle":"2025-02-03T04:24:15.433228Z","shell.execute_reply.started":"2025-02-03T04:21:35.638908Z","shell.execute_reply":"2025-02-03T04:24:15.432138Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2025-02-03 04:21:50.972225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-02-03 04:21:51.163142: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-02-03 04:21:51.220504: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n\u001b[2;36m2025-02-03 04:21:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m prepare tokenizer                                    \u001b]8;id=990618;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=173598;file:///kaggle/working/sd-scripts/library/train_util.py#4558\u001b\\\u001b[2m4558\u001b[0m\u001b]8;;\u001b\\\ntokenizer_config.json: 100%|███████████████████| 905/905 [00:00<00:00, 4.76MB/s]\nvocab.json: 100%|████████████████████████████| 961k/961k [00:00<00:00, 9.13MB/s]\nmerges.txt: 100%|████████████████████████████| 525k/525k [00:00<00:00, 4.15MB/s]\nspecial_tokens_map.json: 100%|█████████████████| 389/389 [00:00<00:00, 2.15MB/s]\ntokenizer.json: 100%|██████████████████████| 2.22M/2.22M [00:00<00:00, 12.2MB/s]\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n\u001b[2;36m2025-02-03 04:22:01\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using DreamBooth method.                           \u001b]8;id=470018;file:///kaggle/working/sd-scripts/train_network.py\u001b\\\u001b[2mtrain_network.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=440152;file:///kaggle/working/sd-scripts/train_network.py#172\u001b\\\u001b[2m172\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m prepare images.                                      \u001b]8;id=893118;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=22518;file:///kaggle/working/sd-scripts/library/train_util.py#1686\u001b\\\u001b[2m1686\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m found directory \u001b[35m/kaggle/working/datasets/\u001b[0m\u001b[95m1_images\u001b[0m    \u001b]8;id=857671;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=391962;file:///kaggle/working/sd-scripts/library/train_util.py#1633\u001b\\\u001b[2m1633\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                    \u001b[0m         contains \u001b[1;36m1\u001b[0m image files                               \u001b[2m                  \u001b[0m\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m No caption file found for \u001b[1;36m1\u001b[0m images. Training will    \u001b]8;id=454110;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631648;file:///kaggle/working/sd-scripts/library/train_util.py#1664\u001b\\\u001b[2m1664\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                    \u001b[0m         continue without captions for these images. If class \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m         token exists, it will be used. \u001b[35m/\u001b[0m                     \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m         1枚の画像にキャプションファイルが見つかりませんでし  \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m         た。これらの画像についてはキャプションなしで学習を続 \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m         行します。class                                      \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m         tokenが存在する場合はそれを使います。                \u001b[2m                  \u001b[0m\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/kaggle/working/datasets/1_images/\u001b[0m\u001b[95mim\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m.png         \u001b]8;id=855513;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=460993;file:///kaggle/working/sd-scripts/library/train_util.py#1671\u001b\\\u001b[2m1671\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m1\u001b[0m train images with repeating.                       \u001b]8;id=847698;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=228542;file:///kaggle/working/sd-scripts/library/train_util.py#1727\u001b\\\u001b[2m1727\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m0\u001b[0m reg images.                                        \u001b]8;id=883100;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=651263;file:///kaggle/working/sd-scripts/library/train_util.py#1730\u001b\\\u001b[2m1730\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m no regularization images \u001b[35m/\u001b[0m                           \u001b]8;id=528673;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=399186;file:///kaggle/working/sd-scripts/library/train_util.py#1735\u001b\\\u001b[2m1735\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                    \u001b[0m         正則化画像が見つかりませんでした                     \u001b[2m                  \u001b[0m\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mDataset \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                                          \u001b]8;id=182290;file:///kaggle/working/sd-scripts/library/config_util.py\u001b\\\u001b[2mconfig_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=624827;file:///kaggle/working/sd-scripts/library/config_util.py#572\u001b\\\u001b[2m572\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                    \u001b[0m           batch_size: \u001b[1;36m2\u001b[0m                                      \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m           resolution: \u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m                             \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m           enable_bucket: \u001b[3;92mTrue\u001b[0m                                \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m           network_multiplier: \u001b[1;36m1.0\u001b[0m                            \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m           min_bucket_reso: \u001b[1;36m256\u001b[0m                               \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m           max_bucket_reso: \u001b[1;36m1024\u001b[0m                              \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m           bucket_reso_steps: \u001b[1;36m64\u001b[0m                              \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m           bucket_no_upscale: \u001b[3;91mFalse\u001b[0m                           \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m                                                              \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m           \u001b[1m[\u001b[0mSubset \u001b[1;36m0\u001b[0m of Dataset \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                            \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             image_dir: \u001b[32m\"/kaggle/working/datasets/1_images\"\u001b[0m   \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             image_count: \u001b[1;36m1\u001b[0m                                   \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             num_repeats: \u001b[1;36m1\u001b[0m                                   \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             shuffle_caption: \u001b[3;91mFalse\u001b[0m                           \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             keep_tokens: \u001b[1;36m0\u001b[0m                                   \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             keep_tokens_separator:                           \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             caption_separator: ,                             \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             secondary_separator: \u001b[3;35mNone\u001b[0m                        \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             enable_wildcard: \u001b[3;91mFalse\u001b[0m                           \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             caption_dropout_rate: \u001b[1;36m0.0\u001b[0m                        \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             caption_dropout_every_n_epoches: \u001b[1;36m0\u001b[0m               \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             caption_tag_dropout_rate: \u001b[1;36m0.0\u001b[0m                    \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             caption_prefix: \u001b[3;35mNone\u001b[0m                             \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             caption_suffix: \u001b[3;35mNone\u001b[0m                             \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             color_aug: \u001b[3;91mFalse\u001b[0m                                 \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             flip_aug: \u001b[3;91mFalse\u001b[0m                                  \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             face_crop_aug_range: \u001b[3;35mNone\u001b[0m                        \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             random_crop: \u001b[3;91mFalse\u001b[0m                               \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             token_warmup_min: \u001b[1;36m1\u001b[0m,                             \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             token_warmup_step: \u001b[1;36m0\u001b[0m,                            \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             alpha_mask: \u001b[3;91mFalse\u001b[0m,                               \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             is_reg: \u001b[3;91mFalse\u001b[0m                                    \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             class_tokens: images                             \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m             caption_extension: .caption                      \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m                                                              \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m                                                              \u001b[2m                  \u001b[0m\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mDataset \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                                          \u001b]8;id=766313;file:///kaggle/working/sd-scripts/library/config_util.py\u001b\\\u001b[2mconfig_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=294213;file:///kaggle/working/sd-scripts/library/config_util.py#578\u001b\\\u001b[2m578\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading image sizes.                                  \u001b]8;id=178566;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=70728;file:///kaggle/working/sd-scripts/library/train_util.py#901\u001b\\\u001b[2m901\u001b[0m\u001b]8;;\u001b\\\n100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 9039.45it/s]\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m make buckets                                          \u001b]8;id=610315;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=514488;file:///kaggle/working/sd-scripts/library/train_util.py#907\u001b\\\u001b[2m907\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m number of images \u001b[1m(\u001b[0mincluding repeats\u001b[1m)\u001b[0m \u001b[35m/\u001b[0m                \u001b]8;id=1882;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=783079;file:///kaggle/working/sd-scripts/library/train_util.py#953\u001b\\\u001b[2m953\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                    \u001b[0m         各bucketの画像枚数（繰り返し回数を含む）              \u001b[2m                 \u001b[0m\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m bucket \u001b[1;36m0\u001b[0m: resolution \u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m, count: \u001b[1;36m1\u001b[0m             \u001b]8;id=328196;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=522665;file:///kaggle/working/sd-scripts/library/train_util.py#958\u001b\\\u001b[2m958\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m mean ar error \u001b[1m(\u001b[0mwithout repeats\u001b[1m)\u001b[0m: \u001b[1;36m0.21978021978021978\u001b[0m  \u001b]8;id=923004;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=203111;file:///kaggle/working/sd-scripts/library/train_util.py#963\u001b\\\u001b[2m963\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m preparing accelerator                              \u001b]8;id=42450;file:///kaggle/working/sd-scripts/train_network.py\u001b\\\u001b[2mtrain_network.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=271493;file:///kaggle/working/sd-scripts/train_network.py#225\u001b\\\u001b[2m225\u001b[0m\u001b]8;;\u001b\\\naccelerator device: cuda\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading model for process \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                        \u001b]8;id=870163;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=318046;file:///kaggle/working/sd-scripts/library/train_util.py#4716\u001b\\\u001b[2m4716\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load StableDiffusion checkpoint:                     \u001b]8;id=229053;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=529202;file:///kaggle/working/sd-scripts/library/train_util.py#4672\u001b\\\u001b[2m4672\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                    \u001b[0m         \u001b[35m/kaggle/working/stable-diffusion-webui-master/models\u001b[0m \u001b[2m                  \u001b[0m\n\u001b[2;36m                    \u001b[0m         \u001b[35m/Stable-diffusion/\u001b[0m\u001b[95mv1-5-pruned-emaonly.safetensors\u001b[0m    \u001b[2m                  \u001b[0m\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m UNet2DConditionModel: \u001b[1;36m64\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m768\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m    \u001b]8;id=838234;file:///kaggle/working/sd-scripts/library/original_unet.py\u001b\\\u001b[2moriginal_unet.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=262674;file:///kaggle/working/sd-scripts/library/original_unet.py#1387\u001b\\\u001b[2m1387\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m2025-02-03 04:22:09\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading u-net: \u001b[1m<\u001b[0m\u001b[1;95mAll\u001b[0m\u001b[39m keys matched successfully\u001b[0m\u001b[1m>\u001b[0m       \u001b]8;id=154100;file:///kaggle/working/sd-scripts/library/model_util.py\u001b\\\u001b[2mmodel_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=325213;file:///kaggle/working/sd-scripts/library/model_util.py#1009\u001b\\\u001b[2m1009\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m2025-02-03 04:22:10\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading vae: \u001b[1m<\u001b[0m\u001b[1;95mAll\u001b[0m\u001b[39m keys matched successfully\u001b[0m\u001b[1m>\u001b[0m         \u001b]8;id=717209;file:///kaggle/working/sd-scripts/library/model_util.py\u001b\\\u001b[2mmodel_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=346236;file:///kaggle/working/sd-scripts/library/model_util.py#1017\u001b\\\u001b[2m1017\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m2025-02-03 04:22:12\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading text encoder: \u001b[1m<\u001b[0m\u001b[1;95mAll\u001b[0m\u001b[39m keys matched \u001b[0m             \u001b]8;id=331556;file:///kaggle/working/sd-scripts/library/model_util.py\u001b\\\u001b[2mmodel_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=640561;file:///kaggle/working/sd-scripts/library/model_util.py#1074\u001b\\\u001b[2m1074\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                    \u001b[0m         \u001b[39msuccessfully\u001b[0m\u001b[1m>\u001b[0m                                        \u001b[2m                  \u001b[0m\nimport network module: networks.lora\n\u001b[2;36m2025-02-03 04:22:13\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m create LoRA network. base dim \u001b[1m(\u001b[0mrank\u001b[1m)\u001b[0m: \u001b[1;36m32\u001b[0m, alpha: \u001b[1;36m16.0\u001b[0m       \u001b]8;id=907343;file:///kaggle/working/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=546678;file:///kaggle/working/sd-scripts/networks/lora.py#935\u001b\\\u001b[2m935\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m neuron dropout: \u001b[33mp\u001b[0m=\u001b[3;35mNone\u001b[0m, rank dropout: \u001b[33mp\u001b[0m=\u001b[3;35mNone\u001b[0m, module        \u001b]8;id=960489;file:///kaggle/working/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=14723;file:///kaggle/working/sd-scripts/networks/lora.py#936\u001b\\\u001b[2m936\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                    \u001b[0m         dropout: \u001b[33mp\u001b[0m=\u001b[3;35mNone\u001b[0m                                             \u001b[2m           \u001b[0m\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m create LoRA for Text Encoder:                              \u001b]8;id=864912;file:///kaggle/working/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=823182;file:///kaggle/working/sd-scripts/networks/lora.py#1030\u001b\\\u001b[2m1030\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m create LoRA for Text Encoder: \u001b[1;36m24\u001b[0m modules.                  \u001b]8;id=868287;file:///kaggle/working/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=909747;file:///kaggle/working/sd-scripts/networks/lora.py#1035\u001b\\\u001b[2m1035\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m create LoRA for U-Net: \u001b[1;36m192\u001b[0m modules.                        \u001b]8;id=912755;file:///kaggle/working/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=66043;file:///kaggle/working/sd-scripts/networks/lora.py#1043\u001b\\\u001b[2m1043\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m enable LoRA for text encoder: \u001b[1;36m24\u001b[0m modules                   \u001b]8;id=842368;file:///kaggle/working/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=149416;file:///kaggle/working/sd-scripts/networks/lora.py#1084\u001b\\\u001b[2m1084\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m enable LoRA for U-Net: \u001b[1;36m192\u001b[0m modules                         \u001b]8;id=335601;file:///kaggle/working/sd-scripts/networks/lora.py\u001b\\\u001b[2mlora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=917595;file:///kaggle/working/sd-scripts/networks/lora.py#1089\u001b\\\u001b[2m1089\u001b[0m\u001b]8;;\u001b\\\nprepare optimizer, data loader etc.\n\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m use AdamW optimizer | \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                             \u001b]8;id=578045;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=305230;file:///kaggle/working/sd-scripts/library/train_util.py#4365\u001b\\\u001b[2m4365\u001b[0m\u001b]8;;\u001b\\\nrunning training / 学習開始\n  num train images * repeats / 学習画像の数×繰り返し回数: 1\n  num reg images / 正則化画像の数: 0\n  num batches per epoch / 1epochのバッチ数: 1\n  num epochs / epoch数: 200\n  batch size per device / バッチサイズ: 2\n  gradient accumulation steps / 勾配を合計するステップ数 = 1\n  total optimization steps / 学習ステップ数: 200\nsteps:   0%|                                            | 0/200 [00:00<?, ?it/s]\nepoch 1/200\n\u001b[2;36m2025-02-03 04:22:26\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m1\u001b[0m      \u001b]8;id=656670;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=916989;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   0%|                   | 1/200 [00:02<07:07,  2.15s/it, avr_loss=0.0134]\nepoch 2/200\n\u001b[2;36m2025-02-03 04:22:28\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m2\u001b[0m      \u001b]8;id=371483;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=483098;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   1%|▏                   | 2/200 [00:02<04:23,  1.33s/it, avr_loss=0.536]\nepoch 3/200\n\u001b[2;36m2025-02-03 04:22:29\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m3\u001b[0m      \u001b]8;id=739590;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=897574;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   2%|▎                  | 3/200 [00:03<03:28,  1.06s/it, avr_loss=0.0103]\nepoch 4/200\n\u001b[2;36m2025-02-03 04:22:29\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m4\u001b[0m      \u001b]8;id=524355;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=166722;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   2%|▍                   | 4/200 [00:03<03:00,  1.08it/s, avr_loss=0.294]\nepoch 5/200\n\u001b[2;36m2025-02-03 04:22:30\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m5\u001b[0m      \u001b]8;id=970254;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=967802;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   2%|▌                   | 5/200 [00:04<02:43,  1.19it/s, avr_loss=0.252]\nepoch 6/200\n\u001b[2;36m2025-02-03 04:22:30\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m6\u001b[0m      \u001b]8;id=109888;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=902079;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   3%|▌                   | 6/200 [00:04<02:32,  1.27it/s, avr_loss=0.682]\nepoch 7/200\n\u001b[2;36m2025-02-03 04:22:31\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m7\u001b[0m      \u001b]8;id=535375;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=822825;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   4%|▋                 | 7/200 [00:05<02:23,  1.34it/s, avr_loss=0.00512]\nepoch 8/200\n\u001b[2;36m2025-02-03 04:22:31\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m8\u001b[0m      \u001b]8;id=428944;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=175534;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   4%|▊                   | 8/200 [00:05<02:17,  1.40it/s, avr_loss=0.642]\nepoch 9/200\n\u001b[2;36m2025-02-03 04:22:32\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m9\u001b[0m      \u001b]8;id=651958;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=690613;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   4%|▊                  | 9/200 [00:06<02:12,  1.44it/s, avr_loss=0.0627]\nepoch 10/200\n\u001b[2;36m2025-02-03 04:22:32\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m10\u001b[0m     \u001b]8;id=653372;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=354668;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   5%|▉                  | 10/200 [00:06<02:08,  1.48it/s, avr_loss=0.265]\nepoch 11/200\n\u001b[2;36m2025-02-03 04:22:33\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m11\u001b[0m     \u001b]8;id=525637;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=85228;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   6%|█                  | 11/200 [00:07<02:04,  1.52it/s, avr_loss=0.415]\nepoch 12/200\n\u001b[2;36m2025-02-03 04:22:33\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m12\u001b[0m     \u001b]8;id=821674;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=762779;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   6%|█                 | 12/200 [00:07<02:01,  1.55it/s, avr_loss=0.0436]\nepoch 13/200\n\u001b[2;36m2025-02-03 04:22:34\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m13\u001b[0m     \u001b]8;id=114673;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=181203;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   6%|█▏                 | 13/200 [00:08<01:58,  1.58it/s, avr_loss=0.613]\nepoch 14/200\n\u001b[2;36m2025-02-03 04:22:34\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m14\u001b[0m     \u001b]8;id=497568;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=302314;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   7%|█▎                | 14/200 [00:08<01:56,  1.60it/s, avr_loss=0.0591]\nepoch 15/200\n\u001b[2;36m2025-02-03 04:22:35\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m15\u001b[0m     \u001b]8;id=809740;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=469954;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   8%|█▎                | 15/200 [00:09<01:54,  1.62it/s, avr_loss=0.0085]\nepoch 16/200\n\u001b[2;36m2025-02-03 04:22:35\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m16\u001b[0m     \u001b]8;id=243646;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=614283;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   8%|█▌                 | 16/200 [00:09<01:52,  1.64it/s, avr_loss=0.506]\nepoch 17/200\n\u001b[2;36m2025-02-03 04:22:36\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m17\u001b[0m     \u001b]8;id=941506;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=200824;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   8%|█▌                | 17/200 [00:10<01:50,  1.66it/s, avr_loss=0.0159]\nepoch 18/200\n\u001b[2;36m2025-02-03 04:22:36\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m18\u001b[0m     \u001b]8;id=302168;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=992841;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:   9%|█▉                   | 18/200 [00:10<01:49,  1.67it/s, avr_loss=0.3]\nepoch 19/200\n\u001b[2;36m2025-02-03 04:22:37\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m19\u001b[0m     \u001b]8;id=556721;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=733672;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  10%|█▋                | 19/200 [00:11<01:47,  1.68it/s, avr_loss=0.0893]\nepoch 20/200\n\u001b[2;36m2025-02-03 04:22:37\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m20\u001b[0m     \u001b]8;id=75870;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=515382;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  10%|█▉                 | 20/200 [00:11<01:46,  1.69it/s, avr_loss=0.162]\nepoch 21/200\n\u001b[2;36m2025-02-03 04:22:38\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m21\u001b[0m     \u001b]8;id=440113;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=659973;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  10%|█▊               | 21/200 [00:12<01:45,  1.70it/s, avr_loss=0.00964]\nepoch 22/200\n\u001b[2;36m2025-02-03 04:22:38\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m22\u001b[0m     \u001b]8;id=10245;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=820903;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  11%|██                 | 22/200 [00:12<01:43,  1.71it/s, avr_loss=0.307]\nepoch 23/200\n\u001b[2;36m2025-02-03 04:22:39\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m23\u001b[0m     \u001b]8;id=168212;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703864;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  12%|██▏                | 23/200 [00:13<01:42,  1.72it/s, avr_loss=0.364]\nepoch 24/200\n\u001b[2;36m2025-02-03 04:22:39\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m24\u001b[0m     \u001b]8;id=23771;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=821161;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  12%|██▍                 | 24/200 [00:13<01:41,  1.73it/s, avr_loss=0.27]\nepoch 25/200\n\u001b[2;36m2025-02-03 04:22:40\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m25\u001b[0m     \u001b]8;id=570634;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=989059;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  12%|██▏              | 25/200 [00:14<01:41,  1.73it/s, avr_loss=0.00667]\nepoch 26/200\n\u001b[2;36m2025-02-03 04:22:40\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m26\u001b[0m     \u001b]8;id=810686;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=680099;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  13%|██▍                | 26/200 [00:15<01:40,  1.73it/s, avr_loss=0.463]\nepoch 27/200\n\u001b[2;36m2025-02-03 04:22:41\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m27\u001b[0m     \u001b]8;id=898246;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=616773;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  14%|██▍               | 27/200 [00:15<01:39,  1.74it/s, avr_loss=0.0622]\nepoch 28/200\n\u001b[2;36m2025-02-03 04:22:41\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m28\u001b[0m     \u001b]8;id=607587;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=154315;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  14%|██▌               | 28/200 [00:16<01:38,  1.74it/s, avr_loss=0.0233]\nepoch 29/200\n\u001b[2;36m2025-02-03 04:22:42\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m29\u001b[0m     \u001b]8;id=810919;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=67464;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  14%|██▊                | 29/200 [00:16<01:37,  1.75it/s, avr_loss=0.219]\nepoch 30/200\n\u001b[2;36m2025-02-03 04:22:42\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m30\u001b[0m     \u001b]8;id=995833;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=967452;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  15%|██▊                | 30/200 [00:17<01:36,  1.76it/s, avr_loss=0.153]\nepoch 31/200\n\u001b[2;36m2025-02-03 04:22:43\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m31\u001b[0m     \u001b]8;id=608820;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=364354;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  16%|██▉                | 31/200 [00:17<01:35,  1.76it/s, avr_loss=0.631]\nepoch 32/200\n\u001b[2;36m2025-02-03 04:22:43\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m32\u001b[0m     \u001b]8;id=606114;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=287011;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  16%|███                | 32/200 [00:18<01:34,  1.77it/s, avr_loss=0.189]\nepoch 33/200\n\u001b[2;36m2025-02-03 04:22:44\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m33\u001b[0m     \u001b]8;id=626561;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=486963;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  16%|███▏               | 33/200 [00:18<01:34,  1.78it/s, avr_loss=0.175]\nepoch 34/200\n\u001b[2;36m2025-02-03 04:22:44\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m34\u001b[0m     \u001b]8;id=422881;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=929375;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  17%|███               | 34/200 [00:19<01:33,  1.78it/s, avr_loss=0.0245]\nepoch 35/200\n\u001b[2;36m2025-02-03 04:22:45\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m35\u001b[0m     \u001b]8;id=511165;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=120047;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  18%|███▎               | 35/200 [00:19<01:32,  1.79it/s, avr_loss=0.451]\nepoch 36/200\n\u001b[2;36m2025-02-03 04:22:45\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m36\u001b[0m     \u001b]8;id=535673;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=213031;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  18%|███▍               | 36/200 [00:20<01:31,  1.79it/s, avr_loss=0.372]\nepoch 37/200\n\u001b[2;36m2025-02-03 04:22:46\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m37\u001b[0m     \u001b]8;id=348514;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=127249;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  18%|███▏             | 37/200 [00:20<01:31,  1.79it/s, avr_loss=0.00502]\nepoch 38/200\n\u001b[2;36m2025-02-03 04:22:47\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m38\u001b[0m     \u001b]8;id=366677;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=362597;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  19%|███▌               | 38/200 [00:21<01:30,  1.79it/s, avr_loss=0.016]\nepoch 39/200\n\u001b[2;36m2025-02-03 04:22:47\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m39\u001b[0m     \u001b]8;id=393077;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=238666;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  20%|███▋               | 39/200 [00:21<01:29,  1.80it/s, avr_loss=0.686]\nepoch 40/200\n\u001b[2;36m2025-02-03 04:22:48\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m40\u001b[0m     \u001b]8;id=970754;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=571056;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  20%|███▍             | 40/200 [00:22<01:28,  1.80it/s, avr_loss=0.00673]\nepoch 41/200\n\u001b[2;36m2025-02-03 04:22:48\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m41\u001b[0m     \u001b]8;id=904840;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=903733;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  20%|███▋              | 41/200 [00:22<01:27,  1.81it/s, avr_loss=0.0111]\nepoch 42/200\n\u001b[2;36m2025-02-03 04:22:49\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m42\u001b[0m     \u001b]8;id=120452;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=848585;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  21%|███▊              | 42/200 [00:23<01:27,  1.81it/s, avr_loss=0.0124]\nepoch 43/200\n\u001b[2;36m2025-02-03 04:22:49\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m43\u001b[0m     \u001b]8;id=707504;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=191104;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  22%|███▊              | 43/200 [00:23<01:26,  1.81it/s, avr_loss=0.0587]\nepoch 44/200\n\u001b[2;36m2025-02-03 04:22:50\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m44\u001b[0m     \u001b]8;id=971416;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=795748;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  22%|████▏              | 44/200 [00:24<01:25,  1.82it/s, avr_loss=0.315]\nepoch 45/200\n\u001b[2;36m2025-02-03 04:22:50\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m45\u001b[0m     \u001b]8;id=919145;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=828882;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  22%|████▎              | 45/200 [00:24<01:25,  1.82it/s, avr_loss=0.619]\nepoch 46/200\n\u001b[2;36m2025-02-03 04:22:51\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m46\u001b[0m     \u001b]8;id=852270;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=549455;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  23%|████▎              | 46/200 [00:25<01:24,  1.82it/s, avr_loss=0.157]\nepoch 47/200\n\u001b[2;36m2025-02-03 04:22:51\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m47\u001b[0m     \u001b]8;id=850412;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=507596;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  24%|████▍              | 47/200 [00:25<01:23,  1.83it/s, avr_loss=0.321]\nepoch 48/200\n\u001b[2;36m2025-02-03 04:22:52\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m48\u001b[0m     \u001b]8;id=779561;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=388963;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  24%|████▌              | 48/200 [00:26<01:23,  1.83it/s, avr_loss=0.671]\nepoch 49/200\n\u001b[2;36m2025-02-03 04:22:52\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m49\u001b[0m     \u001b]8;id=671929;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=555398;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  24%|████▋              | 49/200 [00:26<01:22,  1.83it/s, avr_loss=0.462]\nepoch 50/200\n\u001b[2;36m2025-02-03 04:22:53\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m50\u001b[0m     \u001b]8;id=331525;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=234935;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  25%|████▊              | 50/200 [00:27<01:21,  1.84it/s, avr_loss=0.305]\nepoch 51/200\n\u001b[2;36m2025-02-03 04:22:53\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m51\u001b[0m     \u001b]8;id=42565;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=24729;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  26%|████▊              | 51/200 [00:27<01:21,  1.84it/s, avr_loss=0.302]\nepoch 52/200\n\u001b[2;36m2025-02-03 04:22:54\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m52\u001b[0m     \u001b]8;id=484459;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=395758;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  26%|████▋             | 52/200 [00:28<01:20,  1.84it/s, avr_loss=0.0321]\nepoch 53/200\n\u001b[2;36m2025-02-03 04:22:54\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m53\u001b[0m     \u001b]8;id=993454;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=585245;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  26%|████▊             | 53/200 [00:28<01:19,  1.84it/s, avr_loss=0.0133]\nepoch 54/200\n\u001b[2;36m2025-02-03 04:22:55\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m54\u001b[0m     \u001b]8;id=121004;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=399618;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  27%|█████▏             | 54/200 [00:29<01:19,  1.85it/s, avr_loss=0.162]\nepoch 55/200\n\u001b[2;36m2025-02-03 04:22:55\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m55\u001b[0m     \u001b]8;id=510211;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=504214;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  28%|████▋            | 55/200 [00:29<01:18,  1.85it/s, avr_loss=0.00851]\nepoch 56/200\n\u001b[2;36m2025-02-03 04:22:56\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m56\u001b[0m     \u001b]8;id=24867;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=997877;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  28%|█████▎             | 56/200 [00:30<01:17,  1.85it/s, avr_loss=0.634]\nepoch 57/200\n\u001b[2;36m2025-02-03 04:22:56\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m57\u001b[0m     \u001b]8;id=337326;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=527533;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  28%|█████▍             | 57/200 [00:30<01:17,  1.85it/s, avr_loss=0.324]\nepoch 58/200\n\u001b[2;36m2025-02-03 04:22:57\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m58\u001b[0m     \u001b]8;id=318014;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=549991;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  29%|█████▏            | 58/200 [00:31<01:16,  1.85it/s, avr_loss=0.0782]\nepoch 59/200\n\u001b[2;36m2025-02-03 04:22:57\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m59\u001b[0m     \u001b]8;id=674274;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=978770;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  30%|█████▌             | 59/200 [00:31<01:16,  1.85it/s, avr_loss=0.164]\nepoch 60/200\n\u001b[2;36m2025-02-03 04:22:58\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m60\u001b[0m     \u001b]8;id=891162;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=248290;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  30%|█████▍            | 60/200 [00:32<01:15,  1.86it/s, avr_loss=0.0968]\nepoch 61/200\n\u001b[2;36m2025-02-03 04:22:58\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m61\u001b[0m     \u001b]8;id=558981;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=964061;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  30%|█████▊             | 61/200 [00:32<01:14,  1.86it/s, avr_loss=0.398]\nepoch 62/200\n\u001b[2;36m2025-02-03 04:22:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m62\u001b[0m     \u001b]8;id=585088;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=843272;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  31%|█████▉             | 62/200 [00:33<01:14,  1.86it/s, avr_loss=0.157]\nepoch 63/200\n\u001b[2;36m2025-02-03 04:22:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m63\u001b[0m     \u001b]8;id=508152;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=875882;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  32%|█████▉             | 63/200 [00:33<01:13,  1.86it/s, avr_loss=0.209]\nepoch 64/200\n\u001b[2;36m2025-02-03 04:23:00\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m64\u001b[0m     \u001b]8;id=121097;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=134001;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  32%|██████             | 64/200 [00:34<01:13,  1.86it/s, avr_loss=0.273]\nepoch 65/200\n\u001b[2;36m2025-02-03 04:23:00\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m65\u001b[0m     \u001b]8;id=169876;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=51302;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  32%|█████▊            | 65/200 [00:34<01:12,  1.86it/s, avr_loss=0.0562]\nepoch 66/200\n\u001b[2;36m2025-02-03 04:23:01\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m66\u001b[0m     \u001b]8;id=616158;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=669564;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  33%|██████▌             | 66/200 [00:35<01:11,  1.87it/s, avr_loss=0.72]\nepoch 67/200\n\u001b[2;36m2025-02-03 04:23:01\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m67\u001b[0m     \u001b]8;id=948063;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=166128;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  34%|█████▋           | 67/200 [00:35<01:11,  1.87it/s, avr_loss=0.00715]\nepoch 68/200\n\u001b[2;36m2025-02-03 04:23:02\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m68\u001b[0m     \u001b]8;id=297900;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=150379;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  34%|██████▍            | 68/200 [00:36<01:10,  1.87it/s, avr_loss=0.347]\nepoch 69/200\n\u001b[2;36m2025-02-03 04:23:02\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m69\u001b[0m     \u001b]8;id=119603;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=398211;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  34%|██████▌            | 69/200 [00:36<01:10,  1.87it/s, avr_loss=0.533]\nepoch 70/200\n\u001b[2;36m2025-02-03 04:23:03\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m70\u001b[0m     \u001b]8;id=669244;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=459274;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  35%|██████▋            | 70/200 [00:37<01:09,  1.87it/s, avr_loss=0.288]\nepoch 71/200\n\u001b[2;36m2025-02-03 04:23:03\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m71\u001b[0m     \u001b]8;id=97032;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=70376;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  36%|██████▋            | 71/200 [00:37<01:08,  1.87it/s, avr_loss=0.566]\nepoch 72/200\n\u001b[2;36m2025-02-03 04:23:04\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m72\u001b[0m     \u001b]8;id=622533;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=912809;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  36%|██████▊            | 72/200 [00:38<01:08,  1.87it/s, avr_loss=0.408]\nepoch 73/200\n\u001b[2;36m2025-02-03 04:23:04\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m73\u001b[0m     \u001b]8;id=554952;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=509856;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  36%|██████▌           | 73/200 [00:38<01:07,  1.87it/s, avr_loss=0.0403]\nepoch 74/200\n\u001b[2;36m2025-02-03 04:23:05\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m74\u001b[0m     \u001b]8;id=362563;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=698759;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  37%|██████▋           | 74/200 [00:39<01:07,  1.88it/s, avr_loss=0.0138]\nepoch 75/200\n\u001b[2;36m2025-02-03 04:23:05\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m75\u001b[0m     \u001b]8;id=700303;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=643073;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  38%|███████▉             | 75/200 [00:39<01:06,  1.88it/s, avr_loss=0.3]\nepoch 76/200\n\u001b[2;36m2025-02-03 04:23:06\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m76\u001b[0m     \u001b]8;id=957122;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=258808;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  38%|███████▏           | 76/200 [00:40<01:06,  1.88it/s, avr_loss=0.126]\nepoch 77/200\n\u001b[2;36m2025-02-03 04:23:06\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m77\u001b[0m     \u001b]8;id=391267;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=699329;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  38%|██████▉           | 77/200 [00:41<01:05,  1.88it/s, avr_loss=0.0102]\nepoch 78/200\n\u001b[2;36m2025-02-03 04:23:07\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m78\u001b[0m     \u001b]8;id=453766;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=972;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  39%|███████▍           | 78/200 [00:41<01:04,  1.88it/s, avr_loss=0.275]\nepoch 79/200\n\u001b[2;36m2025-02-03 04:23:07\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m79\u001b[0m     \u001b]8;id=962229;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=875761;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  40%|███████▌           | 79/200 [00:42<01:04,  1.88it/s, avr_loss=0.343]\nepoch 80/200\n\u001b[2;36m2025-02-03 04:23:08\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m80\u001b[0m     \u001b]8;id=573448;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=258224;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  40%|███████▏          | 80/200 [00:42<01:03,  1.88it/s, avr_loss=0.0763]\nepoch 81/200\n\u001b[2;36m2025-02-03 04:23:08\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m81\u001b[0m     \u001b]8;id=651529;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=919715;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  40%|██████▉          | 81/200 [00:43<01:03,  1.88it/s, avr_loss=0.00683]\nepoch 82/200\n\u001b[2;36m2025-02-03 04:23:09\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m82\u001b[0m     \u001b]8;id=780250;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=266557;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  41%|███████▊           | 82/200 [00:43<01:02,  1.88it/s, avr_loss=0.029]\nepoch 83/200\n\u001b[2;36m2025-02-03 04:23:09\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m83\u001b[0m     \u001b]8;id=152917;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=505991;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  42%|███████▍          | 83/200 [00:44<01:02,  1.88it/s, avr_loss=0.0955]\nepoch 84/200\n\u001b[2;36m2025-02-03 04:23:10\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m84\u001b[0m     \u001b]8;id=351589;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=66265;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  42%|███████▉           | 84/200 [00:44<01:01,  1.89it/s, avr_loss=0.325]\nepoch 85/200\n\u001b[2;36m2025-02-03 04:23:10\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m85\u001b[0m     \u001b]8;id=147241;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=330952;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  42%|████████           | 85/200 [00:45<01:00,  1.89it/s, avr_loss=0.016]\nepoch 86/200\n\u001b[2;36m2025-02-03 04:23:11\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m86\u001b[0m     \u001b]8;id=341381;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=547286;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  43%|████████▏          | 86/200 [00:45<01:00,  1.89it/s, avr_loss=0.183]\nepoch 87/200\n\u001b[2;36m2025-02-03 04:23:11\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m87\u001b[0m     \u001b]8;id=4442;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=949547;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  44%|███████▊          | 87/200 [00:46<00:59,  1.88it/s, avr_loss=0.0752]\nepoch 88/200\n\u001b[2;36m2025-02-03 04:23:12\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m88\u001b[0m     \u001b]8;id=867890;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=476688;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  44%|████████▎          | 88/200 [00:46<00:59,  1.88it/s, avr_loss=0.157]\nepoch 89/200\n\u001b[2;36m2025-02-03 04:23:13\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m89\u001b[0m     \u001b]8;id=884530;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=702444;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  44%|████████▍          | 89/200 [00:47<00:58,  1.88it/s, avr_loss=0.694]\nepoch 90/200\n\u001b[2;36m2025-02-03 04:23:13\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m90\u001b[0m     \u001b]8;id=759323;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=513648;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  45%|████████▌          | 90/200 [00:47<00:58,  1.88it/s, avr_loss=0.482]\nepoch 91/200\n\u001b[2;36m2025-02-03 04:23:14\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m91\u001b[0m     \u001b]8;id=45644;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=825653;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  46%|████████▋          | 91/200 [00:48<00:57,  1.88it/s, avr_loss=0.543]\nepoch 92/200\n\u001b[2;36m2025-02-03 04:23:14\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m92\u001b[0m     \u001b]8;id=68474;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=707181;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  46%|████████▋          | 92/200 [00:48<00:57,  1.89it/s, avr_loss=0.536]\nepoch 93/200\n\u001b[2;36m2025-02-03 04:23:15\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m93\u001b[0m     \u001b]8;id=338744;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=27146;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  46%|███████▉         | 93/200 [00:49<00:56,  1.89it/s, avr_loss=0.00497]\nepoch 94/200\n\u001b[2;36m2025-02-03 04:23:15\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m94\u001b[0m     \u001b]8;id=505145;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=770950;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  47%|████████▉          | 94/200 [00:49<00:56,  1.89it/s, avr_loss=0.558]\nepoch 95/200\n\u001b[2;36m2025-02-03 04:23:16\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m95\u001b[0m     \u001b]8;id=825932;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=605946;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  48%|█████████          | 95/200 [00:50<00:55,  1.89it/s, avr_loss=0.295]\nepoch 96/200\n\u001b[2;36m2025-02-03 04:23:16\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m96\u001b[0m     \u001b]8;id=282643;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=257020;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  48%|████████▋         | 96/200 [00:50<00:55,  1.89it/s, avr_loss=0.0723]\nepoch 97/200\n\u001b[2;36m2025-02-03 04:23:17\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m97\u001b[0m     \u001b]8;id=942246;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=556602;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  48%|█████████▏         | 97/200 [00:51<00:54,  1.89it/s, avr_loss=0.847]\nepoch 98/200\n\u001b[2;36m2025-02-03 04:23:17\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m98\u001b[0m     \u001b]8;id=652676;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=369802;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  49%|█████████▎         | 98/200 [00:51<00:54,  1.89it/s, avr_loss=0.131]\nepoch 99/200\n\u001b[2;36m2025-02-03 04:23:18\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m99\u001b[0m     \u001b]8;id=84714;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=176774;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  50%|████████▉         | 99/200 [00:52<00:53,  1.89it/s, avr_loss=0.0857]\nepoch 100/200\n\u001b[2;36m2025-02-03 04:23:18\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m100\u001b[0m    \u001b]8;id=942747;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=535849;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  50%|████████▌        | 100/200 [00:52<00:52,  1.89it/s, avr_loss=0.0857]\nsaving checkpoint: /kaggle/working/lora_art_model/at-step00000100.safetensors\nsteps:  50%|█████████         | 100/200 [00:53<00:53,  1.87it/s, avr_loss=0.281]\nepoch 101/200\n\u001b[2;36m2025-02-03 04:23:19\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m101\u001b[0m    \u001b]8;id=528879;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=759450;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  50%|████████▌        | 101/200 [00:54<00:52,  1.87it/s, avr_loss=0.0885]\nepoch 102/200\n\u001b[2;36m2025-02-03 04:23:20\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m102\u001b[0m    \u001b]8;id=747779;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=779592;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  51%|█████████▏        | 102/200 [00:54<00:52,  1.87it/s, avr_loss=0.392]\nepoch 103/200\n\u001b[2;36m2025-02-03 04:23:20\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m103\u001b[0m    \u001b]8;id=728767;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=323518;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  52%|████████▊        | 103/200 [00:55<00:51,  1.87it/s, avr_loss=0.0577]\nepoch 104/200\n\u001b[2;36m2025-02-03 04:23:21\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m104\u001b[0m    \u001b]8;id=140432;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=77786;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  52%|█████████▎        | 104/200 [00:55<00:51,  1.87it/s, avr_loss=0.175]\nepoch 105/200\n\u001b[2;36m2025-02-03 04:23:21\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m105\u001b[0m    \u001b]8;id=597076;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=270857;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  52%|█████████▍        | 105/200 [00:56<00:50,  1.87it/s, avr_loss=0.436]\nepoch 106/200\n\u001b[2;36m2025-02-03 04:23:22\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m106\u001b[0m    \u001b]8;id=331338;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=910464;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  53%|█████████        | 106/200 [00:56<00:50,  1.87it/s, avr_loss=0.0106]\nepoch 107/200\n\u001b[2;36m2025-02-03 04:23:22\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m107\u001b[0m    \u001b]8;id=743436;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=550972;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  54%|█████████        | 107/200 [00:57<00:49,  1.88it/s, avr_loss=0.0102]\nepoch 108/200\n\u001b[2;36m2025-02-03 04:23:23\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m108\u001b[0m    \u001b]8;id=72333;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=609013;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  54%|█████████▋        | 108/200 [00:57<00:49,  1.88it/s, avr_loss=0.168]\nepoch 109/200\n\u001b[2;36m2025-02-03 04:23:23\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m109\u001b[0m    \u001b]8;id=29468;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=87785;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  55%|████████▋       | 109/200 [00:58<00:48,  1.88it/s, avr_loss=0.00464]\nepoch 110/200\n\u001b[2;36m2025-02-03 04:23:24\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m110\u001b[0m    \u001b]8;id=870322;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=83341;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  55%|█████████▎       | 110/200 [00:58<00:47,  1.88it/s, avr_loss=0.0789]\nepoch 111/200\n\u001b[2;36m2025-02-03 04:23:24\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m111\u001b[0m    \u001b]8;id=622177;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=559632;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  56%|█████████▍       | 111/200 [00:59<00:47,  1.88it/s, avr_loss=0.0273]\nepoch 112/200\n\u001b[2;36m2025-02-03 04:23:25\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m112\u001b[0m    \u001b]8;id=133715;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=832048;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  56%|██████████        | 112/200 [00:59<00:46,  1.88it/s, avr_loss=0.174]\nepoch 113/200\n\u001b[2;36m2025-02-03 04:23:26\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m113\u001b[0m    \u001b]8;id=305794;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=470572;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  56%|██████████▏       | 113/200 [01:00<00:46,  1.88it/s, avr_loss=0.109]\nepoch 114/200\n\u001b[2;36m2025-02-03 04:23:26\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m114\u001b[0m    \u001b]8;id=508848;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=407323;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  57%|██████████▎       | 114/200 [01:00<00:45,  1.88it/s, avr_loss=0.131]\nepoch 115/200\n\u001b[2;36m2025-02-03 04:23:27\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m115\u001b[0m    \u001b]8;id=401097;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=879666;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  57%|██████████▎       | 115/200 [01:01<00:45,  1.88it/s, avr_loss=0.309]\nepoch 116/200\n\u001b[2;36m2025-02-03 04:23:27\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m116\u001b[0m    \u001b]8;id=875899;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=36556;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  58%|██████████▍       | 116/200 [01:01<00:44,  1.88it/s, avr_loss=0.104]\nepoch 117/200\n\u001b[2;36m2025-02-03 04:23:28\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m117\u001b[0m    \u001b]8;id=946846;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=23207;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  58%|██████████▌       | 117/200 [01:02<00:44,  1.88it/s, avr_loss=0.628]\nepoch 118/200\n\u001b[2;36m2025-02-03 04:23:28\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m118\u001b[0m    \u001b]8;id=44417;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=942306;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  59%|██████████       | 118/200 [01:02<00:43,  1.88it/s, avr_loss=0.0104]\nepoch 119/200\n\u001b[2;36m2025-02-03 04:23:29\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m119\u001b[0m    \u001b]8;id=560824;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=131371;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  60%|██████████▋       | 119/200 [01:03<00:43,  1.88it/s, avr_loss=0.245]\nepoch 120/200\n\u001b[2;36m2025-02-03 04:23:29\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m120\u001b[0m    \u001b]8;id=191718;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=101228;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  60%|██████████▏      | 120/200 [01:03<00:42,  1.88it/s, avr_loss=0.0241]\nepoch 121/200\n\u001b[2;36m2025-02-03 04:23:30\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m121\u001b[0m    \u001b]8;id=825102;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=710317;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  60%|███████████▍       | 121/200 [01:04<00:41,  1.88it/s, avr_loss=0.32]\nepoch 122/200\n\u001b[2;36m2025-02-03 04:23:30\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m122\u001b[0m    \u001b]8;id=327351;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=794120;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  61%|██████████▉       | 122/200 [01:04<00:41,  1.88it/s, avr_loss=0.108]\nepoch 123/200\n\u001b[2;36m2025-02-03 04:23:31\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m123\u001b[0m    \u001b]8;id=872291;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=606383;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  62%|█████████▊      | 123/200 [01:05<00:40,  1.88it/s, avr_loss=0.00721]\nepoch 124/200\n\u001b[2;36m2025-02-03 04:23:31\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m124\u001b[0m    \u001b]8;id=605312;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=830910;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  62%|███████████▊       | 124/200 [01:05<00:40,  1.88it/s, avr_loss=0.52]\nepoch 125/200\n\u001b[2;36m2025-02-03 04:23:32\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m125\u001b[0m    \u001b]8;id=783829;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=392280;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  62%|██████████▋      | 125/200 [01:06<00:39,  1.89it/s, avr_loss=0.0272]\nepoch 126/200\n\u001b[2;36m2025-02-03 04:23:32\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m126\u001b[0m    \u001b]8;id=13814;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=678549;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  63%|███████████▎      | 126/200 [01:06<00:39,  1.89it/s, avr_loss=0.603]\nepoch 127/200\n\u001b[2;36m2025-02-03 04:23:33\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m127\u001b[0m    \u001b]8;id=787305;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=984579;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  64%|███████████▍      | 127/200 [01:07<00:38,  1.89it/s, avr_loss=0.102]\nepoch 128/200\n\u001b[2;36m2025-02-03 04:23:33\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m128\u001b[0m    \u001b]8;id=690598;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=775821;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  64%|███████████▌      | 128/200 [01:07<00:38,  1.89it/s, avr_loss=0.266]\nepoch 129/200\n\u001b[2;36m2025-02-03 04:23:34\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m129\u001b[0m    \u001b]8;id=103863;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=746515;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  64%|██████████▎     | 129/200 [01:08<00:37,  1.89it/s, avr_loss=0.00395]\nepoch 130/200\n\u001b[2;36m2025-02-03 04:23:34\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m130\u001b[0m    \u001b]8;id=447068;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=857553;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  65%|███████████      | 130/200 [01:08<00:37,  1.89it/s, avr_loss=0.0218]\nepoch 131/200\n\u001b[2;36m2025-02-03 04:23:35\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m131\u001b[0m    \u001b]8;id=493725;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=547763;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  66%|███████████▊      | 131/200 [01:09<00:36,  1.89it/s, avr_loss=0.862]\nepoch 132/200\n\u001b[2;36m2025-02-03 04:23:35\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m132\u001b[0m    \u001b]8;id=953160;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=822265;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  66%|███████████▉      | 132/200 [01:09<00:35,  1.89it/s, avr_loss=0.258]\nepoch 133/200\n\u001b[2;36m2025-02-03 04:23:36\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m133\u001b[0m    \u001b]8;id=931911;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=336409;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  66%|███████████▉      | 133/200 [01:10<00:35,  1.89it/s, avr_loss=0.476]\nepoch 134/200\n\u001b[2;36m2025-02-03 04:23:36\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m134\u001b[0m    \u001b]8;id=539974;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=328392;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  67%|████████████      | 134/200 [01:10<00:34,  1.89it/s, avr_loss=0.245]\nepoch 135/200\n\u001b[2;36m2025-02-03 04:23:37\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m135\u001b[0m    \u001b]8;id=737711;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=946806;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  68%|███████████▍     | 135/200 [01:11<00:34,  1.89it/s, avr_loss=0.0257]\nepoch 136/200\n\u001b[2;36m2025-02-03 04:23:37\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m136\u001b[0m    \u001b]8;id=9943;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=494186;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  68%|████████████▏     | 136/200 [01:11<00:33,  1.89it/s, avr_loss=0.118]\nepoch 137/200\n\u001b[2;36m2025-02-03 04:23:38\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m137\u001b[0m    \u001b]8;id=33278;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=399052;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  68%|████████████▎     | 137/200 [01:12<00:33,  1.89it/s, avr_loss=0.102]\nepoch 138/200\n\u001b[2;36m2025-02-03 04:23:38\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m138\u001b[0m    \u001b]8;id=470049;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=336901;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  69%|████████████▍     | 138/200 [01:12<00:32,  1.89it/s, avr_loss=0.385]\nepoch 139/200\n\u001b[2;36m2025-02-03 04:23:39\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m139\u001b[0m    \u001b]8;id=13930;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=270810;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  70%|████████████▌     | 139/200 [01:13<00:32,  1.89it/s, avr_loss=0.608]\nepoch 140/200\n\u001b[2;36m2025-02-03 04:23:39\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m140\u001b[0m    \u001b]8;id=944426;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=636760;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  70%|████████████▌     | 140/200 [01:13<00:31,  1.89it/s, avr_loss=0.299]\nepoch 141/200\n\u001b[2;36m2025-02-03 04:23:40\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m141\u001b[0m    \u001b]8;id=59265;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=291821;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  70%|███████████▉     | 141/200 [01:14<00:31,  1.89it/s, avr_loss=0.0803]\nepoch 142/200\n\u001b[2;36m2025-02-03 04:23:40\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m142\u001b[0m    \u001b]8;id=589837;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=369528;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  71%|████████████     | 142/200 [01:14<00:30,  1.89it/s, avr_loss=0.0997]\nepoch 143/200\n\u001b[2;36m2025-02-03 04:23:41\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m143\u001b[0m    \u001b]8;id=883801;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=719484;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  72%|████████████▊     | 143/200 [01:15<00:30,  1.89it/s, avr_loss=0.396]\nepoch 144/200\n\u001b[2;36m2025-02-03 04:23:41\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m144\u001b[0m    \u001b]8;id=557682;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=663425;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  72%|████████████▉     | 144/200 [01:16<00:29,  1.89it/s, avr_loss=0.192]\nepoch 145/200\n\u001b[2;36m2025-02-03 04:23:42\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m145\u001b[0m    \u001b]8;id=21389;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=895738;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  72%|█████████████▊     | 145/200 [01:16<00:29,  1.90it/s, avr_loss=0.37]\nepoch 146/200\n\u001b[2;36m2025-02-03 04:23:42\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m146\u001b[0m    \u001b]8;id=57221;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=993409;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  73%|█████████████▏    | 146/200 [01:17<00:28,  1.90it/s, avr_loss=0.361]\nepoch 147/200\n\u001b[2;36m2025-02-03 04:23:43\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m147\u001b[0m    \u001b]8;id=266535;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=339204;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  74%|█████████████▏    | 147/200 [01:17<00:27,  1.90it/s, avr_loss=0.114]\nepoch 148/200\n\u001b[2;36m2025-02-03 04:23:43\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m148\u001b[0m    \u001b]8;id=264719;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=346160;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  74%|███████████▊    | 148/200 [01:18<00:27,  1.89it/s, avr_loss=0.00724]\nepoch 149/200\n\u001b[2;36m2025-02-03 04:23:44\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m149\u001b[0m    \u001b]8;id=175660;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=633002;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  74%|████████████▋    | 149/200 [01:18<00:26,  1.89it/s, avr_loss=0.0534]\nepoch 150/200\n\u001b[2;36m2025-02-03 04:23:45\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m150\u001b[0m    \u001b]8;id=834879;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=178951;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  75%|████████████▊    | 150/200 [01:19<00:26,  1.89it/s, avr_loss=0.0212]\nepoch 151/200\n\u001b[2;36m2025-02-03 04:23:45\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m151\u001b[0m    \u001b]8;id=412931;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=828248;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  76%|█████████████▌    | 151/200 [01:19<00:25,  1.89it/s, avr_loss=0.194]\nepoch 152/200\n\u001b[2;36m2025-02-03 04:23:46\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m152\u001b[0m    \u001b]8;id=612044;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=536928;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  76%|████████████▏   | 152/200 [01:20<00:25,  1.89it/s, avr_loss=0.00629]\nepoch 153/200\n\u001b[2;36m2025-02-03 04:23:46\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m153\u001b[0m    \u001b]8;id=944741;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=456572;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  76%|█████████████    | 153/200 [01:20<00:24,  1.89it/s, avr_loss=0.0723]\nepoch 154/200\n\u001b[2;36m2025-02-03 04:23:47\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m154\u001b[0m    \u001b]8;id=127936;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=475782;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  77%|█████████████▊    | 154/200 [01:21<00:24,  1.89it/s, avr_loss=0.326]\nepoch 155/200\n\u001b[2;36m2025-02-03 04:23:47\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m155\u001b[0m    \u001b]8;id=796203;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=17892;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  78%|█████████████▉    | 155/200 [01:21<00:23,  1.89it/s, avr_loss=0.008]\nepoch 156/200\n\u001b[2;36m2025-02-03 04:23:48\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m156\u001b[0m    \u001b]8;id=400915;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=491543;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  78%|██████████████▊    | 156/200 [01:22<00:23,  1.89it/s, avr_loss=0.67]\nepoch 157/200\n\u001b[2;36m2025-02-03 04:23:48\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m157\u001b[0m    \u001b]8;id=239393;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=18684;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  78%|████████████▌   | 157/200 [01:22<00:22,  1.89it/s, avr_loss=0.00861]\nepoch 158/200\n\u001b[2;36m2025-02-03 04:23:49\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m158\u001b[0m    \u001b]8;id=930436;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=901773;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  79%|███████████████    | 158/200 [01:23<00:22,  1.89it/s, avr_loss=0.29]\nepoch 159/200\n\u001b[2;36m2025-02-03 04:23:49\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m159\u001b[0m    \u001b]8;id=6680;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=109764;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  80%|█████████████▌   | 159/200 [01:23<00:21,  1.90it/s, avr_loss=0.0165]\nepoch 160/200\n\u001b[2;36m2025-02-03 04:23:50\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m160\u001b[0m    \u001b]8;id=449982;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=204676;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  80%|█████████████▌   | 160/200 [01:24<00:21,  1.90it/s, avr_loss=0.0484]\nepoch 161/200\n\u001b[2;36m2025-02-03 04:23:50\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m161\u001b[0m    \u001b]8;id=35234;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=931826;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  80%|██████████████▍   | 161/200 [01:24<00:20,  1.90it/s, avr_loss=0.134]\nepoch 162/200\n\u001b[2;36m2025-02-03 04:23:51\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m162\u001b[0m    \u001b]8;id=604697;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=868544;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  81%|██████████████▌   | 162/200 [01:25<00:20,  1.90it/s, avr_loss=0.325]\nepoch 163/200\n\u001b[2;36m2025-02-03 04:23:51\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m163\u001b[0m    \u001b]8;id=972111;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=241989;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  82%|█████████████▊   | 163/200 [01:25<00:19,  1.90it/s, avr_loss=0.0864]\nepoch 164/200\n\u001b[2;36m2025-02-03 04:23:52\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m164\u001b[0m    \u001b]8;id=821698;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=906756;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  82%|██████████████▊   | 164/200 [01:26<00:18,  1.90it/s, avr_loss=0.116]\nepoch 165/200\n\u001b[2;36m2025-02-03 04:23:52\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m165\u001b[0m    \u001b]8;id=364076;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=824487;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  82%|██████████████   | 165/200 [01:26<00:18,  1.90it/s, avr_loss=0.0228]\nepoch 166/200\n\u001b[2;36m2025-02-03 04:23:53\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m166\u001b[0m    \u001b]8;id=594278;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=19432;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  83%|██████████████   | 166/200 [01:27<00:17,  1.90it/s, avr_loss=0.0363]\nepoch 167/200\n\u001b[2;36m2025-02-03 04:23:53\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m167\u001b[0m    \u001b]8;id=102447;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=587446;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  84%|███████████████   | 167/200 [01:27<00:17,  1.90it/s, avr_loss=0.443]\nepoch 168/200\n\u001b[2;36m2025-02-03 04:23:54\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m168\u001b[0m    \u001b]8;id=665686;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=517080;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  84%|██████████████▎  | 168/200 [01:28<00:16,  1.90it/s, avr_loss=0.0219]\nepoch 169/200\n\u001b[2;36m2025-02-03 04:23:54\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m169\u001b[0m    \u001b]8;id=551809;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464962;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  84%|██████████████▎  | 169/200 [01:28<00:16,  1.90it/s, avr_loss=0.0597]\nepoch 170/200\n\u001b[2;36m2025-02-03 04:23:55\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m170\u001b[0m    \u001b]8;id=809970;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=322432;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  85%|███████████████▎  | 170/200 [01:29<00:15,  1.90it/s, avr_loss=0.128]\nepoch 171/200\n\u001b[2;36m2025-02-03 04:23:55\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m171\u001b[0m    \u001b]8;id=903158;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=922864;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  86%|███████████████▍  | 171/200 [01:30<00:15,  1.90it/s, avr_loss=0.388]\nepoch 172/200\n\u001b[2;36m2025-02-03 04:23:56\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m172\u001b[0m    \u001b]8;id=690857;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=121047;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  86%|███████████████▍  | 172/200 [01:30<00:14,  1.90it/s, avr_loss=0.245]\nepoch 173/200\n\u001b[2;36m2025-02-03 04:23:56\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m173\u001b[0m    \u001b]8;id=617560;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=917247;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  86%|██████████████▋  | 173/200 [01:31<00:14,  1.90it/s, avr_loss=0.0824]\nepoch 174/200\n\u001b[2;36m2025-02-03 04:23:57\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m174\u001b[0m    \u001b]8;id=808396;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=826032;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  87%|██████████████▊  | 174/200 [01:31<00:13,  1.90it/s, avr_loss=0.0175]\nepoch 175/200\n\u001b[2;36m2025-02-03 04:23:57\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m175\u001b[0m    \u001b]8;id=827724;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=165266;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  88%|██████████████▉  | 175/200 [01:32<00:13,  1.90it/s, avr_loss=0.0173]\nepoch 176/200\n\u001b[2;36m2025-02-03 04:23:58\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m176\u001b[0m    \u001b]8;id=20702;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=286667;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  88%|██████████████▉  | 176/200 [01:32<00:12,  1.90it/s, avr_loss=0.0905]\nepoch 177/200\n\u001b[2;36m2025-02-03 04:23:58\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m177\u001b[0m    \u001b]8;id=75729;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=516178;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  88%|███████████████  | 177/200 [01:33<00:12,  1.90it/s, avr_loss=0.0392]\nepoch 178/200\n\u001b[2;36m2025-02-03 04:23:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m178\u001b[0m    \u001b]8;id=927281;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=241393;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  89%|████████████████  | 178/200 [01:33<00:11,  1.90it/s, avr_loss=0.416]\nepoch 179/200\n\u001b[2;36m2025-02-03 04:23:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m179\u001b[0m    \u001b]8;id=286077;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=485635;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  90%|███████████████▏ | 179/200 [01:34<00:11,  1.90it/s, avr_loss=0.0247]\nepoch 180/200\n\u001b[2;36m2025-02-03 04:24:00\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m180\u001b[0m    \u001b]8;id=64505;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=311599;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  90%|███████████████▎ | 180/200 [01:34<00:10,  1.90it/s, avr_loss=0.0923]\nepoch 181/200\n\u001b[2;36m2025-02-03 04:24:00\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m181\u001b[0m    \u001b]8;id=956441;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=361642;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  90%|███████████████▍ | 181/200 [01:35<00:09,  1.90it/s, avr_loss=0.0611]\nepoch 182/200\n\u001b[2;36m2025-02-03 04:24:01\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m182\u001b[0m    \u001b]8;id=609356;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=230289;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  91%|████████████████▍ | 182/200 [01:35<00:09,  1.90it/s, avr_loss=0.188]\nepoch 183/200\n\u001b[2;36m2025-02-03 04:24:02\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m183\u001b[0m    \u001b]8;id=362934;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=238407;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  92%|███████████████▌ | 183/200 [01:36<00:08,  1.90it/s, avr_loss=0.0285]\nepoch 184/200\n\u001b[2;36m2025-02-03 04:24:02\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m184\u001b[0m    \u001b]8;id=339477;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=241194;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  92%|████████████████▌ | 184/200 [01:36<00:08,  1.90it/s, avr_loss=0.234]\nepoch 185/200\n\u001b[2;36m2025-02-03 04:24:03\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m185\u001b[0m    \u001b]8;id=828168;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=825127;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  92%|████████████████▋ | 185/200 [01:37<00:07,  1.90it/s, avr_loss=0.227]\nepoch 186/200\n\u001b[2;36m2025-02-03 04:24:03\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m186\u001b[0m    \u001b]8;id=118275;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=406704;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  93%|████████████████▋ | 186/200 [01:37<00:07,  1.90it/s, avr_loss=0.101]\nepoch 187/200\n\u001b[2;36m2025-02-03 04:24:04\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m187\u001b[0m    \u001b]8;id=195557;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=425040;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  94%|████████████████▊ | 187/200 [01:38<00:06,  1.90it/s, avr_loss=0.102]\nepoch 188/200\n\u001b[2;36m2025-02-03 04:24:04\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m188\u001b[0m    \u001b]8;id=344894;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=676250;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  94%|███████████████▉ | 188/200 [01:38<00:06,  1.91it/s, avr_loss=0.0149]\nepoch 189/200\n\u001b[2;36m2025-02-03 04:24:05\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m189\u001b[0m    \u001b]8;id=181933;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=112974;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  94%|████████████████ | 189/200 [01:39<00:05,  1.91it/s, avr_loss=0.0667]\nepoch 190/200\n\u001b[2;36m2025-02-03 04:24:05\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m190\u001b[0m    \u001b]8;id=409818;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=874945;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  95%|█████████████████ | 190/200 [01:39<00:05,  1.91it/s, avr_loss=0.689]\nepoch 191/200\n\u001b[2;36m2025-02-03 04:24:06\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m191\u001b[0m    \u001b]8;id=958467;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=767217;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  96%|████████████████▏| 191/200 [01:40<00:04,  1.91it/s, avr_loss=0.0586]\nepoch 192/200\n\u001b[2;36m2025-02-03 04:24:06\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m192\u001b[0m    \u001b]8;id=836297;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=539203;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  96%|████████████████▎| 192/200 [01:40<00:04,  1.91it/s, avr_loss=0.0171]\nepoch 193/200\n\u001b[2;36m2025-02-03 04:24:07\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m193\u001b[0m    \u001b]8;id=1106;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=600548;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  96%|█████████████████▎| 193/200 [01:41<00:03,  1.91it/s, avr_loss=0.237]\nepoch 194/200\n\u001b[2;36m2025-02-03 04:24:07\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m194\u001b[0m    \u001b]8;id=11435;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=701182;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  97%|████████████████▍| 194/200 [01:41<00:03,  1.91it/s, avr_loss=0.0419]\nepoch 195/200\n\u001b[2;36m2025-02-03 04:24:08\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m195\u001b[0m    \u001b]8;id=278480;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=87463;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  98%|███████████████▌| 195/200 [01:42<00:02,  1.91it/s, avr_loss=0.00855]\nepoch 196/200\n\u001b[2;36m2025-02-03 04:24:08\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m196\u001b[0m    \u001b]8;id=635306;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=848510;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  98%|█████████████████▋| 196/200 [01:42<00:02,  1.91it/s, avr_loss=0.197]\nepoch 197/200\n\u001b[2;36m2025-02-03 04:24:09\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m197\u001b[0m    \u001b]8;id=159189;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=315094;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  98%|████████████████▋| 197/200 [01:43<00:01,  1.91it/s, avr_loss=0.0166]\nepoch 198/200\n\u001b[2;36m2025-02-03 04:24:09\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m198\u001b[0m    \u001b]8;id=618812;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=333771;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps:  99%|█████████████████▊| 198/200 [01:43<00:01,  1.91it/s, avr_loss=0.451]\nepoch 199/200\n\u001b[2;36m2025-02-03 04:24:10\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m199\u001b[0m    \u001b]8;id=421882;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=622974;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps: 100%|█████████████████▉| 199/200 [01:44<00:00,  1.91it/s, avr_loss=0.107]\nepoch 200/200\n\u001b[2;36m2025-02-03 04:24:10\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m epoch is incremented. current_epoch: \u001b[1;36m0\u001b[0m, epoch: \u001b[1;36m200\u001b[0m    \u001b]8;id=210370;file:///kaggle/working/sd-scripts/library/train_util.py\u001b\\\u001b[2mtrain_util.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=209399;file:///kaggle/working/sd-scripts/library/train_util.py#693\u001b\\\u001b[2m693\u001b[0m\u001b]8;;\u001b\\\nsteps: 100%|██████████████████| 200/200 [01:44<00:00,  1.91it/s, avr_loss=0.107]\nsaving checkpoint: /kaggle/working/lora_art_model/at-step00000200.safetensors\nsteps: 100%|████████████████| 200/200 [01:45<00:00,  1.90it/s, avr_loss=0.00339]\nsaving checkpoint: /kaggle/working/lora_art_model/last.safetensors\n\u001b[2;36m2025-02-03 04:24:12\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m model saved.                                      \u001b]8;id=967048;file:///kaggle/working/sd-scripts/train_network.py\u001b\\\u001b[2mtrain_network.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=566528;file:///kaggle/working/sd-scripts/train_network.py#1104\u001b\\\u001b[2m1104\u001b[0m\u001b]8;;\u001b\\\nsteps: 100%|████████████████| 200/200 [01:45<00:00,  1.89it/s, avr_loss=0.00339]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!mkdir -p /kaggle/working/stable-diffusion-webui-master/models/Lora/\n!cp /kaggle/working/lora_art_model/last.safetensors /kaggle/working/stable-diffusion-webui-master/models/Lora/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T04:25:33.185131Z","iopub.execute_input":"2025-02-03T04:25:33.185483Z","iopub.status.idle":"2025-02-03T04:25:33.480455Z","shell.execute_reply.started":"2025-02-03T04:25:33.185459Z","shell.execute_reply":"2025-02-03T04:25:33.479485Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"","metadata":{"id":"u9xupk1I4mZf","trusted":true},"outputs":[],"execution_count":null}]}